
Different versions may have different order... and the man page is not as tight to the  actual facts


{A} -> {Q|R} -> {G|M|F) -> {P} -> I -> {U} -> D -> --------------+
                                                                 |
                                                             storage
                                                                 |
C <--------------------------------------------------------------+


  Dev   CPU      Seq    Time        PID    E  Ty
  8,4   18        1     0.000000000 30916  A  WS 86730056 + 8 <- (253,1) 44785480 		Remap dm-1 to sda4
  8,0   18        2     0.000000923 30916  A  WS 173237576 + 8 <- (8,4) 86730056		Remap sda4 to sda
  8,0   18        3     0.000001721 30916  Q  WS 173237576 + 8 [mysqld]                         Queue (make_request()?)
  8,0   18        4     0.000004895 30916  G  WS 173237576 + 8 [mysqld]                         New request
  8,0   18        5     0.000006937 30916  P   N [mysqld]					Plug drain
  8,0   18        6     0.000007879 30916  I  WS 173237576 + 8 [mysqld]				Insert into queue
  8,0   18        0     0.000011862     0  m   N cfq30916S / insert_request
  8,0   18        0     0.000013135     0  m   N cfq30916S / add_to_rr
  8,0   18        7     0.000019898 30916  U   N [mysqld] 1
  8,0   18        0     0.000022715     0  m   N cfq workload slice:100
  8,0   18        0     0.000024446     0  m   N cfq30916S / set_active wl_prio:0 wl_type:1
  8,0   18        0     0.000026738     0  m   N cfq30916S / fifo=(null)
  8,0   18        0     0.000027820     0  m   N cfq30916S / dispatch_insert
  8,0   18        0     0.000030090     0  m   N cfq30916S / dispatched a request
  8,0   18        0     0.000031289     0  m   N cfq30916S / activate rq, drv=1
  8,0   18        8     0.000031626 30916  D  WS 173237576 + 8 [mysqld]				Dispatch to driver
  8,0    6        1     0.000115301     0  C  WS 173237576 + 8 [0]				Complete @iodone


A - "remAp"  remap for stacked devices, typical is relative LBA to physical LBA for example relative LBA 0 in sda1 is the physical LVA sector of the first sector
             in partition A. Similar remapping for dm devices.
Q - "Queued" this notes the intent to queue i/o at given location. no real requests exists yet.
R - "Requeue" io "failed" but will be retried


G - "Get"    get request, to send any type of request to a block device a struct request container {for BIOs} must be allocated first (__make_request()?)
M - "Merge"  back merge, a previously insterted request structure exists that ends on the boundary of where this i/o begins, so the i/o scheduler can merge them together
F - "Front merge" same as back merge, except this i/o ends where previously inserted requests starts.

     >> note really the above should reference BIOs as starting ending within the request container.  that is the request only reflects the BIOs within
     >> the request structure.  nit pick/detail but re-inforcing that the BIOs are merged into 1 io 'request'

I - "Inserted" a request structure is being sent to the i/o scheduler for addition to the internal quewue and later service by the driver.  The
               requst is fully formed at this time.

     >> this is interesting in that "sent to i/o scheduler" implies that the make_request() which is inside iosched is not part of the 
     >> io scheduler with reference to 'I event.  But really make request is not part of the previous layers of the io stack...

P - "Plug" when i/o is queued to a previously empty block device queue, linux will plug the queue in anticipation of future
           ios being added before this data is needed. 

     >> in order to create opportunity for merging of io -- larger io is more efficient io -- the drain is plugged to prevent 
     >> io from freeing flowing to the device as small io without the benefit of being able to take advantag of potential merging
     >> opportunity.  With cfq io scheduler personality there is a 'slice idle' time that is associated with plug/unplug.  Reducing
     >> the slice idle time can reduce the plug/unplug time.  Plugging the scheduler is especially useful at dirty page flush time,
     >> because typically a bunch of dirty pages are flushed sequentially in a rapid fashion -- essentially simultaneously

U - "Unplug" some request data already queued in the device, start sending requests to the driver.  This may happen automatically if
             a timeout period has passed (see 'T' event) or if a number of requests have been added to the queue.

     >> "the queue" is the queue within the io personality.  Since NVMe devices have "none" for io scheduler personality, there is no
     >> queue, there can be no plug/unplug events, no I events, etc.  For cfq, there are quite literally a ton of queues, having 200-
     >> 300 queues (ok, really subqueues) is not uncommon.  Whereas deadline has just two queues - read and write.  Note that only
     >> cfq can be nice'd as it is the only one that can create new subqueues with priority in relationship to other subqueues.
     

D - "Dispatched" a request that previously resided on the block layer queue or in the i/o scheduler has been sent to the driver
    
     >> kinda, but NVMe breaks this completely in that a) there is no i/o scheduler {personality} for NVMe drives, and b) io to NVMe
     >> are not queued (since the queue is associated with the i/o scheduler personality {cfq|deadline|noop|none} where "none" is no
     >> io scheduler at all.  The term "io scheduler" is overloaded as it applies to both the whole create request structure and the
     >> sub-part that actually "schedules" the io... but even "schedule" is a bit of a misnomer in that its just a elevator sort in
     >> some fashion.

C - "Completed" a previously issued request has been completed.  The output will detail the sector and size of that request, as well
                as the success or failure of it

     >> at iodone() time.

       B -- bounced The data pages attached to this bio are not reachable by the hardware and must be bounced to a lower memory location. This causes a big slowdown in
           i/o  performance,  since  the  data  must be copied to/from kernel buffers. Usually this can be fixed with using better hardware -- either a better i/o con-
           troller, or a platform with an IOMMU.

       S -- sleep No available request structures were available, so the issuer has to wait for one to be freed.

       T -- unplug due to timer If nobody requests the i/o that was queued after plugging the queue, Linux will automatically unplug it  after  a  defined  period  has
           passed.

       X  --  split On raid or device mapper setups, an incoming i/o may straddle a device or internal zone and needs to be chopped up into smaller pieces for service.
           This may indicate a performance problem due to a bad setup of that raid/dm device, but may also just be part of normal boundary conditions.  dm  is  notably
           bad at this and will clone lots of i/o.



